# Simulation Studies {#performance}

The accuracy of LTV-SOBI algorithm principally depends on the source signals and mixture themselves, especially on the assumptions of uncorrelatedness and stationarity. Nevertheless, compared with SOBI, LTV-SOBI could be embedded with extra accuracy losses due to its relatively more complex mixture and associating algorithms. Despite being mathematically negligible in each step of the algorithm, the inherent losses can accumulate in autocovariance decomposition, approximate joint diagonalization and deriving $\boldsymbol{\mathcal E}$ and $\boldsymbol \Omega_0$. Precision is further compromised when `nearPD` has to enforce in case of non-positive semi-definite matrices. In contemplation of addressing time-varying characteristics, modification to existing BSS metrics is needed.

## Extension of Minimal Distance Index

The minimal distance index, denoted as MD, was initially introduced by Ilmonen [-@ilmonen2010new]to measure the ICA algorithm performance by comparing true mixing matrix $\boldsymbol \Omega$ and estimated unmixing matrix $\widehat{\boldsymbol W}$. For a non-time-varying model, MD-index is defined as [adapted @ilmonen2010new], 

\begin{equation}
\text{MD} (\widehat{ \boldsymbol {W}}) = \frac 1 {\sqrt{p-1}} \inf\limits_{ \boldsymbol C \in \mathcal C} || \boldsymbol C \widehat{ \boldsymbol {W}} \boldsymbol \Omega - \boldsymbol I_p||
(\#eq:md)
\end{equation}

where $\mathcal C$ is the set of matrices that allows permutation and scale ambiguity, i.e. each row and column contains exactly one non-zero element. MD-index is an elegant measure for the majority of the BSS algorithms, though regrettably, it could not address the time-varying structure.

The true mixing matrix $\boldsymbol \Omega_t$ is varying over the time $t=1,2,\dots,T$ in TV-SOS model, and same for $\widehat{ \boldsymbol W_1}$. Therefore, this thesis proposes a time-varying version of the MD-index as defined in Equation \@ref(eq:tvmd),

\begin{equation}
\text{tvMD}(\{\widehat{ \boldsymbol W_1}, \widehat{ \boldsymbol W_2}, \dots, \widehat{ \boldsymbol W_T}\}) = \frac 1 T \sum\limits_{t=1}^T \text{MD}(\widehat{ \boldsymbol W_t})
(\#eq:tvmd)
\end{equation}

Since TV-SOS model \@ref(eq:tvsobi) determines all $\widehat{\boldsymbol W_t} = \widehat{\boldsymbol \Omega_t}^{-1}$ by the pseudo initial mixing matrix $\boldsymbol \Omega_0$ and the time varying factor $\boldsymbol{\mathcal E}$, the tvMD can be determined once LTV-SOBI algorithm is completed and the true mixing is known.

Since tvMD is technically a mean value of MD-indies over time, it has a value between $0$ and $1$ by central limit theorem, and the smaller value the better separation.

## Extension of Signal-to-Inference Ratio

In information processing, researchers tend to decompose the restored signals into four parts, namely target signals, interference from other sources, noise and artifacts from separation and evaluation algorithm. The decomposition can be written as [adapted @na2013performance; @vincent2006performance],

\begin{equation}
\boldsymbol x = \boldsymbol s_\text{signal} + \boldsymbol s_\text{interf} + \boldsymbol e_\text{noise} + \boldsymbol e_\text{artif}
(\#eq:foursignal)
\end{equation}

The target signal $\boldsymbol s_\text{signal}$ is not necessarily the exact source signal. Instead, some careful transformation of a source is permissible due to the identifiability issue in BSS, and it is common to allow scale and permutation transform. In particular, permutation and scaling do not usually affect signal interpretation. Some literature marks interference as $\boldsymbol e_\text{interf}$ when falsely mixing of sources is regarded as an error even though it is originated from sources. For example, the restored signal series II mainly corresponds to source series IV, but also have a partial mixture from source series I. In this case, the former is undoubtful $\boldsymbol s_\text{signal}$, and the later should be treated as erroneous interference. Preceding BSS researches, especially under information processing domain, use Signal-to-Inference Ratio (SIR) to measure the similarity between true and restored signals [@eriksson2000source; @vincent2006performance], and its definition is,

\begin{equation}
\text{SIR}= 10 \log_{10} \frac{|| \boldsymbol s_\text{target} ||^2}{|| \boldsymbol s_\text{interf}||^2}
(\#eq:sir)
\end{equation}

The LTV-SOBI algorithm by nature does not involve any external noise, and even if the noise is present in source signals, it shall become a part of true signals. Further, $\boldsymbol e_\text{artif}$ is assumed to be $\boldsymbol 0$ for simplicity. Assume the restored signal to be $\widehat{\boldsymbol x}$ and the permutation/scaling matrix $\boldsymbol C$ as defined in \@ref(eq:md); the signal decompose of \@ref(eq:foursignal) become,

\begin{equation}
\begin{aligned}
\widehat{\boldsymbol x} &= \boldsymbol {s}_\text{signal} + \boldsymbol s_\text{interf}
\\ &= \boldsymbol {Cx} + (\widehat{ \boldsymbol x} - \boldsymbol {Cx}) 
\end{aligned}
(\#eq:twosignal)
\end{equation}

Without doubt, time-varying factor should be considered, and the extension can be achieved by introducing a time index, i.e. $\widehat{\boldsymbol x}_t = \boldsymbol C_t \boldsymbol x_t + (\widehat{ \boldsymbol x}_t - \boldsymbol C_t \boldsymbol x_t)$. The SIR-index should also be slight modified to include convolution over $t=1,2,\dots,T$.

The SIR-index for TV-SOBI can be further simplified by taking $\boldsymbol C_t = \text{diag}( \boldsymbol \Omega_t \widehat{ \boldsymbol \Omega_t}^{-1})$ after a permutation fix. In practice, the permutation is found by arranging the numerically largest value to diagonal position either row-by-row or column-or-column in $\boldsymbol \Omega_t \widehat{ \boldsymbol \Omega_t}^{-1}$. Finally, the time-varying SIR-index is the measure of all diagonal value against off-diagonal items, and it is formulated as,

\begin{equation}
\text{tvSIR}= 10 \log_{10} \frac{ \sum\limits_{t=1}^T|| \text{diag}( \boldsymbol \Omega_t \widehat{ \boldsymbol \Omega_t}^{-1}) ||^2}{ \sum\limits_{t=1}^T || \text{off}( \boldsymbol \Omega_t \widehat{ \boldsymbol \Omega_t}^{-1})||^2} 
(\#eq:tvsir)
\end{equation}

where, $\boldsymbol \Omega_t \widehat{ \boldsymbol \Omega_t}^{-1} = ( \boldsymbol I + t \boldsymbol{\mathcal E})\boldsymbol \Omega_0 \big[ ( \boldsymbol I + t \widehat{\boldsymbol{\mathcal E}}) \widehat{\boldsymbol \Omega_0}\big]^{-1}$.

SIR and tvSIR do not have a direct connection to each other, but the value is comparable. SIR and tvSIR range from $-\infty$ to $\infty$, and the larger the better. It should also be noted that correlation based SIR (e.g., the implementation in `JADE` package [@miettinen2017blind]) does not require true mixing parameters to be known, but tvSIR will always require so.

## Simulation Result

The performance of LTV-SOBI can be expected to be greatly influenced by signal inherited properties, dimension, length and the scale of mixing matrix. Despite the impossibility to inscribe exact factors that impair the performance, four sets of simulation have been conducted in _R_. Intending to minimize potential bias, the four sets have similar sources of 3-dimensional signal that involve sinusoidal and electrocardiographic (ECG) time-series, together with another moving-average or auto-regressive series. Further, 100 repetitions for each result is performed, and the arithmetic mean is reported, meaning that each point in graph \@ref(fig:resultA) - \@ref(fig:resultD) is the average performance metric from 100 simulations with given parameters.

Four sets of the simulated signal mixture are further sampled into different lengths of the observed mixture. For Set I of $100000 (10^5)$ total length, sample frequencies are set to $1:1,\ 2:1,\ 4:1,\ \dots,  1024:1$ corresponding to $100000, 50000, 25000,\dots, 98$ in observed lengths. Such method manages to objectively reflect how the sampling frequencies (in terms of observed lengths) would affect performance, and it is rather important in case the mixtures are almost continuous (for example, sound). Therefore, the simulation steps can be summarized as,

1. Loop for Set I, II, III and IV;

2. Loop for repetition index from 1 to 100;

3. Simulate 1 source signal of size $10^4$ (or $10^5$), and generate corresponding time-varying mixture of fixed $\boldsymbol \Omega_0 = \begin{bmatrix} \begin{bmatrix} 2 & -6 & 0.5 \end{bmatrix} &  \begin{bmatrix} -9 & 5  & 3 \end{bmatrix} & \begin{bmatrix}  -4 &6 &8\end{bmatrix} \end{bmatrix}'$ but differed $\boldsymbol{\mathcal E}$;

4. Loop for sampling frequencies from $1:1$ to $1024:1$ (or $256:1$), generating observed mixture of different length;

5. Loop for selected lags, $\{1\}, \ \{1,2,3\}, \ \{1,2,\dots,6\}, \ \{1,2,\dots,12\}$;

6. Loop for the diverse algorithms to solve the TV-SOS problem, and report performance metrics.

Differences in Set I to IV are detailed in the table below,

|  | I | II | III | IV |
|---|---|---|---|---|
| $\boldsymbol{\mathcal E}$ | $\boldsymbol M \times 10^{-5}$ | $\boldsymbol M \times 10^{-4}$ | $\boldsymbol M \times 10^{-5}$ | $\boldsymbol M \times 10^{-4}$ |
| Simulated Total Length | $100000\ (10^5)$ | $100000\ (10^5)$ | $10000\ (10^4)$ | $10000\ (10^4)$ |
| Sampling Frequency | 1:1 - 1024:1 | 1:1 - 1024:1 | 1:1 - 512:1 | 1:1 - 512:1 |
| Observed Length | 100000 - 98 | 100000 - 98| 10000 - 40 | 10000 - 40 |

where matrix $\boldsymbol M = \begin{bmatrix} -3 & 6 & -6 \\ -4 &2.5 & 6\\ 9&2.1 &7 \end{bmatrix}$.

Aforementioned $tvSIR$ and $tvMD$, served as a time-varying application of $SIR$ and $MD$ correspondingly, are applied to measure the algorithm performance (in terms of accuracy and capability of restoring the original signals), and results are reported in graph \@ref(fig:resultA) - \@ref(fig:resultD). Each sub-graph defines a specific simulation set with a defined lag parameter used in LTV-SOBI algorithm. The curves visulize the performance influenced by sampling frequencies, which are equivalent to observed signal lengths, and log-scale has been applied to the x-axis. Different algorithms can be distinguished by color or line type.

\@ref(fig:resultA) and \@ref(fig:resultD) presumes to exhibit better performance measured by $tvSIR$ with a larger value, i.e. the higher the points and curves the better. The missing values and other deviations will be deliberated in Chapter \@ref(discussion). With the two graphs, the new LTV-SOBI earns an edge over Yereodr's original TV-SOBI in most cases, while the comparable advantage seems to be diminished with increased observed length. On the other hand, the LTV-SOBI-alt algorithm is relatively insensitive to length, though it could not benefit from the larger size of observed information.

```{r figConfig, include = FALSE}
library(tidyverse)
res_sum$lagT = factor(res_sum$lagT, levels = c("Lag = 1", "Lag = 3", "Lag = 6", "Lag = 12"))

getPlot <- function(criteria, cutoff, setVector, yaxisname, limitsVector){
  m <- unique(res_sum$criteria)[criteria]
  res_sum %>%
    filter(criteria == m, N > cutoff, method != "frjd", lag != 1, seriesT %in% setVector) %>%
    ggplot(aes(N, value, color=method, shape = method, linetype = method)) +
    geom_point(size = 1) + geom_line() + 
    scale_color_brewer(palette = "Set2") +
    scale_x_log10() +
    facet_grid(seriesT~lagT) +
    scale_y_continuous(name=yaxisname, limits=limitsVector) +
    theme_light()
}
```

```{r resultA, fig.cap='Performance measured by tvSIR for Set I and II (the larger the better)', out.width='98%', echo = FALSE, fig.width = 9, fig.height = 4}
print(getPlot(4, 90, c("Set I", "Set II"), "tvSIR", c(0,9)))
```

```{r resultB, results='hide', fig.cap='Performance measured by tvSIR for Set III and IV (the larger the better)', out.width='98%', echo = FALSE, fig.width = 9, fig.height = 4}
suppressWarnings(
  print(getPlot(4, 30, c("Set III", "Set IV"), "tvSIR", c(0,9)))
)
```

Using $tvMD$, \@ref(fig:resultA) and \@ref(fig:resultD) demonstrate better performance with lower value, and LTV-SOBI-alt is comparably the best algorithm in most cases except for simulation Set III; larger observation regularly leads to improved performance. The difference between LTV-SOBI and Yeredor's TVSOBI are essentially minimum.

```{r resultC, fig.cap='Performance measured by tvMD for Set I and II (the smaller the better)', out.width='98%', echo = FALSE, fig.width = 9, fig.height = 4}
print(getPlot(2, 90, c("Set I", "Set II"), "tvMD", c(0.8, 1)))
```

```{r resultD, fig.cap='Performance measured by tvMD for Set III and IV (the smaller the better)', out.width='98%', echo = FALSE, fig.width = 9, fig.height = 4}
print(getPlot(2, 30, c("Set III", "Set IV"), "tvMD", c(0.8, 1)))
```

In conclusion, the extension of $MD$ and $SIR$ grants insights of algorithm performance; the simulation results suggest that LTV-SOS problem could yet be rather challenging, and LTV-SOBI algorithm is a comparably more applicable approach. Nonetheless, the metric is not robust enough under all scenarios, and Chapter \@ref(discussion) will attempt to detail such issue. Finally, the simulation results have to exclude the comparison with ordinary SOBI because of non-compatible metrics; SOBI would be penalized by the time-varying model while benefiting from its ignorance of possible extreme values caused by $\boldsymbol{\mathcal E}$. Supposing the metric were acceptable with SOBI, the results prefer SOBI under large size of observations and LTV-SOBI when observed length is relatively small. 