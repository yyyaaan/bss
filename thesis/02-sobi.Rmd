# Blind Source Separation {#sobi}

Blind Source Separation (BSS) assumes a set of individual source signal $\boldsymbol{z}=(\boldsymbol{z}_1, \boldsymbol{z}_2,\dots,\boldsymbol{z}_p)'$ mixed by a $p\times p$ matrix $\boldsymbol{\Omega}$ and thus produce the mixture $\boldsymbol{x}=(\boldsymbol{x}_1, \boldsymbol{x}_2,\dots,\boldsymbol{x}_p)'$, where the signals themselves can be multidimensional. The mixing mechanism shall satisfy $\boldsymbol x = \boldsymbol \mu + \boldsymbol\Omega \boldsymbol z'$, where $\boldsymbol\mu$ stands for a static location parameter, usually the mean value [@belouchrani1997blind]. Without loss of generality, it can be further assumed that $\boldsymbol x$ embeds the zero-mean property, which can be always achieved through substracting the mean from the mixture, $\boldsymbol x = \boldsymbol x^{\text{obs}}- \boldsymbol\mu$, and would lead to furhter simplified mathematical representation. Further consider the natural time-series data structure in signal, assuming pre-centered data and introducing the temporal subscript of $t=1,2,\dots, T$, the BSS model composed of mixing matrix $\boldsymbol\Omega$, $p$-variate time series $\boldsymbol X_t$ and $\boldsymbol Z_t$ can be presented as,

\begin{equation}
\boldsymbol x_t = \boldsymbol{\Omega z'}_t
(\#eq:BSSModel)
\end{equation}

Albeit mathematical unnecessity, $\boldsymbol{\Omega}$ is defined as a full-rank $p\times p$ matrix. A decrease in dimension of $\boldsymbol{\Omega}$ will allow fewer signal series (less-than-$p$-variate time series) generated from the same mixture $\boldsymbol{x}$. However, it is not necessary due to the fact that the outcome carries real-world information, and the usefulness of a series would be more properly determined with the support of further evidence from both the outcome and source. Consequently, it is a justified choice to force the mixing matrix to be full-rank.

The goal of BSS is to restore the source signals based on the observable mixture, and the above model assures that finding mixing matrix $\boldsymbol{\Omega}$ or unmixing matrix $\boldsymbol{\Gamma}= \boldsymbol{\Omega}^{-1}$ suffices, where the full-rank assumption guarantees the existence of inverse matrix. For notation simplification and clarity, the following paragraphs shall only use $\boldsymbol\Omega$. 

## Ambiguities and Assumptions

The BSS model \@ref(eq:BSSModel) underlies the impossibility to identify $\boldsymbol\Omega$ and $\boldsymbol z$ in a finite closed form because of merely one known item, and thus BSS solution tends to incur [@belouchrani1997blind],

- Permutation ambiguity: the $a$-th series of signal may be confused into $b$-th series in the restored one; however, they are always 1-1 correspondent after sign-correction. The permutation can also include sign ambiguity.
- Scale ambiguity: restored signals can be scaled due since for any scale constant $||a||:\ \boldsymbol x \equiv \big(\boldsymbol\Omega ||a||^{-1} \big) \big(||a|| \boldsymbol z \big)$. The scale constant is usually unknown.

Figure \@ref(fig:ambiguity) illustrates the ambiguity. The observed source is a 4-dimensional signal combining auto-regressive, moving average, sinusoidal and Electrocardiogram(ECG)-like time series. Comparing the left and right plot, source series 2 is clearly mapped into series 1 in restored signals, while series 4 become series 2. The scale of the y-axis intimates the scale ambiguity, though the shape and waveform are highly analogous.

```{r ambiguity, fig.show='hold', fig.cap='Observed vs. restored sources', out.width='50%', echo = FALSE}
load("thesis.rdata")
library(tidyverse)
plot.ts(fig_mixing$source, main = "Observed Source",      ann = FALSE)
plot.ts(fig_mixing$unmix,  main = "SOBI Restored Source", ann = FALSE)
```

Relying on certain (assumed) property/properties in the mixing mechanism, There exist different approaches to solve the BSS problem in terms of identifying the mixing matrix and source signal series. Notably, the Independence Component Analysis (ICA) algorithm assumes statistical independence between series and nongaussian distribution within series, in addition to the optional setting of component number equality between source and mixture [@comon1994independent].

## Stationary Time-Series Source Separation Using Autocovariance Matrices

Focusing on the autocovariance matrices, a second order statistics, the second order source separation (SOS) model seeks to extract the original source signals based on the property of uncorrelatedness. Meanwhile, the source signals are assumed to be weakly stationary, implying that the autocovariances vary only upon the lag $\tau$ but not up to the time point $t$, which are mathematically expressed as $\mathbb E (\boldsymbol z_t \boldsymbol z_{t+\tau}')$ being invariant given $\tau$ for all $t=1,2,\dots,T$. The SOS model states the discrete $p$-variate stochastic process $(\boldsymbol Z_t)_{t=0,\pm1, \pm2}$ as (unobservable) source signals and the (observable) mixture $(\boldsymbol X_t)_{t=0,\pm1, \pm2}$ such that [adapted @miettinen2016separation],

\begin{equation}
\begin{aligned} 
\boldsymbol X_t = \boldsymbol{\Omega}\boldsymbol Z'_t,\ \ &\ t=0,\pm 1,\pm2,\dots
\\ \text{satisfies }(A1)\ & \mathbb E( \boldsymbol Z_t) = \boldsymbol 0 
\\ (A2)\ & \mathbb E( \boldsymbol Z_t \boldsymbol Z_t') = \text{Cov}( \boldsymbol Z_t) = \boldsymbol I_p
\\ (A3)\ & \mathbb E( \boldsymbol Z_t \boldsymbol Z_{t+\tau}') = \boldsymbol\Lambda_\tau \text{ diagonal for all } \tau = 1,2,\dots
\end{aligned}    
(\#eq:SOS)
\end{equation}

$(A1)$ simplifies the model with pre-centered observation; $(A2)$ further restrain the source signals in unit scale, solving the scale ambiguity; and $(A3)$ ensures both stationarity and uncorrelatedness. Given realization of the stochastic progress, this semi-parametric model becomes $\boldsymbol x_t = \boldsymbol\Omega \boldsymbol z_t$ and can thus be solved by joint optimization for the diagonal properties in $(A3)$ under the restriction of $(A2)$ in \@ref(eq:SOS), which become a unique constrained optimization using Lagrange method after proper whitening and/or normalization procedures [@miettinen2016separation]. 

The Second Order Blind Identification (SOBI) solves the BSS problem using second-order statistics when the signal and mixing mechanism obey the SOS model, and commonly autocovariance matrices and the robust correspondent are applied [@belouchrani1997blind; @nordhausen2014robustifying]. The major second-order blind source separation approaches include Algorithm for Multiple Unknown Signals Extraction (AMUSE) by Tong, Soon, Huang and Liu [-@tong1990amuse] and Second Order Blind Identification (SOBI) that originally proposed by Belouchrani, Abed-Meraim, Cardoso and Moulines [-@belouchrani1997blind]. Nordhausen [-@nordhausen2014robustifying] expanded the algorithm to non-stationary time series using locally stationary intervals and further robustifying with average spatial-sign autocovariances on such intervals.
