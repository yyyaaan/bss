{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned} \n",
    "x= zA^T + \\mu\n",
    "\\\\ & z \\text{ is source signal, zero-mean}\n",
    "\\\\ & \\mu \\text{ is location param, }p \\text{-vector}\n",
    "\\\\ & A \\text{ is mixing matrix; } W:= A^{-1} \\text{ unmixing}\n",
    "\\\\\n",
    "\\\\ & W \\text{ is not unique up to signs and scales}\n",
    "\\\\ & W^*=CW,\\ C_{p\\times p} \\text{ has exactly one non-zero in each row and column}\n",
    "\\\\ & \\text{usually define }x_{st}= (x-\\mu)\\Sigma^{-1/2},\\ \\ \\Sigma= \\text{Cov}(x)=AA^T\n",
    "\\end{aligned}$$\n",
    "\n",
    "## Joint Diagonalization\n",
    "\n",
    "$S_1,\\ S_2$ are know symmetric matrices; $W_{p\\times p}$ nonsingular and $D_{p\\times p}$ diagonal.\n",
    "\n",
    "$$\\begin{aligned} \\text{Simultaneous Diag Problem }\n",
    "& \\begin{cases} WS_1 W^T &= I_p \\\\ W S_2 W^T & = D \\end{cases}\n",
    "\\\\\n",
    "\\\\ \\text{Simultaneous Diag Solution }\n",
    "& \\begin{cases} \n",
    "  \\text{1. Solve eigen } & S_1 V^T = V^T \\Lambda_1 \\\\ \n",
    "  \\text{2. Square root } & S_1^{-1/2} = V^T \\Lambda-1 ^{-1/2} V \\\\ \n",
    "  \\text{3. Solve eigen } & \\big( S_1^{-1/2}\\ S_2\\ S_1^{-1/2\\ T} \\big) U^T = U^T \\Lambda_2 \\\\\n",
    "  \\text{Solution: } & W=US_1^{-1/2},\\ D= \\Lambda_2\n",
    "  \\end{cases} \n",
    "\\end{aligned}$$\n",
    "\n",
    "For more matrices, try to make $WS_K W^T$ as diagonal as possible. $\\text{off}(M) = M - \\text{diag}(M)$.\n",
    "\n",
    "$$\\begin{aligned} \n",
    "\\text{To minimize diagonality } & \n",
    "\\begin{cases} \\sum\\limits_{k=1}^K M(WS_K W^T) \\\\  \\\\ M(V):= || \\text{off}(V)||^2 = \\sum\\limits_{i\\neq j}V_{ij}^2 \\text{ as a common choice} \\end{cases}\n",
    "\\\\\n",
    "\\\\ \\text{Approximation Solution }\n",
    "& \\begin{cases} \n",
    "  \\text{1. Whitening } & S_k^*= S_1^{-1/2}\\ S_k\\ S_1^{-1/2\\ T}\\\\\n",
    "  & S_1 \\text{ usually covariance matrix}\\\\\n",
    "  \\text{2. Find orthogonal }U & \\text{minimize }\\sum\\limits_{k=2}^K|| \\text{off}(US_k^* U^T)||^2  \\\\\n",
    "  \\ \\ \\ \\ \\ \\text{(or) }\\iff &\\text{maximize }\\sum\\limits_{k=2}^K|| \\text{diag}(US_k^* U^T)||^2 \\\\\n",
    "  \\text{use algorithms e.g.}& \\text{deflation-based }\\textbf{djd} \\text{; Given's rotation }\\textbf{rjd}\n",
    "\\end{cases} \n",
    "\\end{aligned}$$\n",
    "\n",
    "## Independent Component Analysis\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\\\ \\text{ICA assumptions} \n",
    "& \\begin{cases} \n",
    "    \\text{source components are mutually independent} \\\\\n",
    "    E(z)=0 \\text{ and }E(z^T z) = I_p \\\\\n",
    "    \\text{at most one component is Gaussian} \\\\\n",
    "    \\text{each component is i.i.d}\n",
    "  \\end{cases}\n",
    "\\\\\n",
    "\\\\ \\text{ICA-FOBI}\n",
    "& \\begin{cases} \n",
    "    \\text{find unmixing } W \\ \\begin{cases} WS_1(F_x)W^T = I_p \\\\ WS_2(F_x)W^T = D \\end{cases}\\\\\n",
    "    \\text{ where, } \\begin{aligned} &S_1(F_x)=Cov(x) \\\\ &S_2(F_x) = \\frac{1}{p+2} E \\bigg[ \\big|\\big|S_1^{-1/2} \\big(x-Ex\\big)\\big|\\big|^2  \\big(x-Ex\\big)^T \\big(x-Ex\\big)\\bigg] \\end{aligned}\n",
    "  \\end{cases}\n",
    "\\\\\n",
    "\\\\ \\text{ICA-JADE}\n",
    "& \\begin{cases} \n",
    "    \\text{Fourth order cumulant } & C(M):= E[(x_{st}M x_{st}^T)x_{st}^T x_{st}]-M-M^T - \\text{tr}(M)I_p \\\\\n",
    "    \\text{Joint diagonalize }C(E^{ij}) & E^{ij}=e_i^T e_j,\\ \\ \\ e_k \\ p\\text{-vector containing all 0 but 1 at }k \n",
    "  \\end{cases}\n",
    "\\\\\n",
    "\\\\ \\text{ICA-}k \\text{-JADE}\n",
    "& \\begin{cases} \n",
    "    \\text{same as JADE, but limit to } \\{C(E^{ij}): |i-j|<k\\} \\\\\n",
    "    k \\text{ is guess of largest multiplicity of identical kurosis}\n",
    "  \\end{cases}\n",
    "\\end{aligned}$$\n",
    "\n",
    "## Second Order Source Separation\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\\\ \\text{SOS assumptions}\n",
    "& \\begin{cases} \n",
    "    \\text{(time series) } (z_t)_{t=0,\\pm 1,\\pm 2} \\\\\n",
    "    E(z_t)=0 \\text{ and }E(z_t^T z_t) = I_p \\\\\n",
    "    E(z_t^T z_{t+\\tau }) = D_\\tau \\text{ diagonal }\\forall \\tau \\text{ (stationarity)}\n",
    "  \\end{cases}\n",
    "\\\\\n",
    "\\\\ \\text{SOS-AMUSE}\n",
    "& \\begin{cases} \n",
    "    \\text{Given a lag }\\tau: \\\\ \n",
    "    \\text{find unmixing } W_\\tau \\ \\begin{cases} W_\\tau S_0(F_x)W_\\tau^T = I_p \\\\ W_\\tau S_\\tau(F_x)W_\\tau^T = D_\\tau \\end{cases}\\\\\n",
    "    \\text{ where, } \\begin{aligned} &S_0(F_x)=Cov(x) \\\\ &S_\\tau(F_x) = E \\big[ \\big(x_t-Ex_t\\big)^T \\big(x_{t+\\tau} -Ex_{t}\\big)\\big] \\end{aligned}\n",
    "  \\end{cases}\n",
    "\\\\\n",
    "\\\\ \\text{SOS-SOBI}\n",
    "& \\begin{cases} \n",
    "    \\text{Consider lags }\\tau_1,\\tau_2,\\dots, \\tau_k: \\\\ \n",
    "    \\text{find unmixing } W \\ \\begin{cases} W S_0(F_x)W^T &= I_p \\\\ W S_{\\tau_1}(F_x)W^T &= D_{\\tau_1} \\\\ &\\vdots \\\\ W S_{\\tau_K}(F_x)W^T &= D_{\\tau_K} \\end{cases}\\\\\n",
    "    \\text{then, joint diagonalization. } \\textbf{rjd} \\text{ is preferable}\n",
    "  \\end{cases}\n",
    "\\end{aligned}$$\n",
    "\n",
    "## Nonstationary Source Separation\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\\\ \\text{NSS assumptions}\n",
    "& \\begin{cases} \n",
    "    E(z_t)=0 \\ \\forall t\\\\\n",
    "    E(z_t^T z_t) \\text{ diagonal and positive definite }\\forall t \\\\\n",
    "    E(z_t^T z_{t+\\tau })\\text{ diagonal }\\forall t,\\ \\tau \\text{ (not constant, i.e. non-stationary)}\n",
    "  \\end{cases}\n",
    "\\\\\n",
    "\\\\ & S_{T,\\tau}(F_x):= \\frac 1 {|T|-\\tau} \\sum\\limits_{t\\in T} E \\big[ \\big(x_t-Ex_t\\big)^T \\big(x_{t+\\tau} -Ex_{t}\\big)\\big]\n",
    "\\\\\n",
    "\\\\ \\text{NSS-SD}\n",
    "& \\begin{cases} \n",
    "    \\text{simultaneously diagonalize } S_{T_1,0}(F_x), \\ S_{T_2,0}(F_x) \\\\ \n",
    "    \\text{choose } T_1,\\ T_2\\subset [1,n] \\text{that makes above as different as possible}\n",
    "  \\end{cases}\n",
    "\\\\\n",
    "\\\\ \\text{NSS-JD}\n",
    "& \\begin{cases} \n",
    "    \\text{1. whitening using covariance }S_{[1,n],0}(F_x)\\\\\n",
    "    \\text{2. jointly diagonalize } S_{T_1,0}(F_x), \\ S_{T_2,0}(F_x),\\dots,\\ S_{T_K,0}(F_x)\n",
    "  \\end{cases}\n",
    "\\\\\n",
    "\\\\ \\text{NSS-TD-JD}\n",
    "& \\begin{cases}\n",
    "    \\text{consider time dependence, where some intervals may comply SOS} \\\\\n",
    "    \\text{1. whitening using covariance }S_{[1,n],0}(F_x)\\\\\n",
    "    \\text{2. jointly diagonalize } S_{T_i,\\tau_j}(F_x),\\ i=1,\\dots,K,\\ j=1,\\dots,L\\\\\n",
    "    \\text{length if inteval selection: random effects not too large}\\\\\n",
    "    \\text{number of intervals: } K=12 \\text{ if large enough, each interval }\\gt 100 \\text{ obs}\n",
    "  \\end{cases}  \n",
    "\\end{aligned}$$\n",
    "\n",
    "## SOBI Topic: Stationary Time Series\n",
    "\n",
    "SOS model $\\boldsymbol x_t = \\boldsymbol\\mu + \\boldsymbol\\Omega \\boldsymbol z_t,\\ \\ \\ t =  0, \\pm 1,\\pm2,\\dots$\n",
    "\n",
    "Latent time series are assumed to be uncorrelated and weakly stationary $\\begin{cases} \\text{A1} &E(\\boldsymbol z_t)=0 \\\\ \\text{A1} & E(\\boldsymbol z_t \\boldsymbol z_t') = \\boldsymbol I_p \\\\ \\text{A2} & E(\\boldsymbol z_{t} \\boldsymbol z_{t+\\tau}') = e(\\boldsymbol z_{t+\\tau} \\boldsymbol z_{t}') = \\boldsymbol\\Lambda_\\tau \\text{ is diagonal }\\forall \\tau = 1,2,\\dots \\end{cases}$ \n",
    "\n",
    "Given ts-observations, the goal is to estimate $\\hat{\\boldsymbol \\Gamma}:\\ \\boldsymbol{\\Gamma x}$ has uncorrelated components. Clearly, $\\boldsymbol\\Gamma = \\boldsymbol{C\\Omega}^{-1}$, where $\\boldsymbol C$ has exactly one non-zero element in each row and each column\n",
    "\n",
    "### BSS on Autocovariance Matrix\n",
    "\n",
    "Joint diagonalization; suppose $\\boldsymbol \\mu = \\boldsymbol 0$\n",
    "$$\\begin{aligned} \n",
    "E(\\boldsymbol x_{t} \\boldsymbol x_{t+\\tau}') &= E(\\boldsymbol{\\Omega z}_t \\boldsymbol z' _{t+\\tau} \\boldsymbol\\Omega') = \\boldsymbol{\\Omega\\Lambda}_\\tau \\boldsymbol{ \\Omega}'\n",
    "\\\\ \\Rightarrow \\boldsymbol\\Gamma_\\tau \\text{ satisfies } & \\begin{cases} \\boldsymbol \\Gamma_\\tau E(\\boldsymbol x_{t} \\boldsymbol x_{t}') \\boldsymbol \\Gamma_\\tau' = \\boldsymbol I _p \\\\ \\boldsymbol \\Gamma_\\tau E(\\boldsymbol x_{t} \\boldsymbol x_{t+\\tau}')\\boldsymbol \\Gamma_\\tau' = \\underbrace{ \\boldsymbol P_\\tau \\boldsymbol \\Lambda_\\tau \\boldsymbol P'_\\tau}_{\\text{decreasing ordered } \\boldsymbol\\Lambda_\\tau }\\end{cases} \n",
    "\\end{aligned}$$\n",
    "\n",
    "AMUSE algorithm only consider the unique $\\boldsymbol S_0 = E(\\boldsymbol x_{t} \\boldsymbol x_{t}'), \\ \\boldsymbol S_\\tau = E(\\boldsymbol x_{t} \\boldsymbol x_{t+\\tau}')$.\n",
    "\n",
    "SOBI algorithm consider lags at $\\tau_1, \\dots, \\tau_K$, and find unmixing $\\boldsymbol\\Gamma_{p\\times p} = (\\gamma_1,\\dots,\\gamma_p)'$ by\n",
    "$$\\begin{aligned} \\text{ under constraint } \\boldsymbol {\\Gamma S}_0 \\boldsymbol \\Gamma' = \\boldsymbol I _p\n",
    "\\\\ \\text{minimize } & \\sum\\limits_{k=1}^K \\big|\\big| \\text{off}( \\boldsymbol{\\Gamma S}_k \\boldsymbol \\Gamma ') \\big |\\big|^2 ,\\ \\ \\ \\text{off}( \\boldsymbol S) = \\boldsymbol S - \\text{diag}( \\boldsymbol S)\n",
    "\\\\ \\Leftrightarrow \\text{ maximize } & \\sum\\limits_{k=1}^K \\big|\\big| \\text{diag}( \\boldsymbol{\\Gamma S}_k \\boldsymbol \\Gamma ') \\big |\\big|^2 = \\sum\\limits_{j=1}^p \\sum\\limits_{k=1}^K (\\gamma_j' \\boldsymbol S_k \\gamma_j)^2\n",
    "\\end{aligned}$$\n",
    "\n",
    "Facts: $\\boldsymbol {\\Gamma S}_k \\boldsymbol\\Gamma' = \\boldsymbol I_p \\ \\Rightarrow \\ \\boldsymbol\\Gamma = \\boldsymbol {US}_0^{-1/2}$, where $\\boldsymbol U_{p\\times p} = (u_1,\\dots,u_p)'$ orthogonal.\n",
    "\n",
    "Solving the optimization problem depends on the methdology below.\n",
    "\n",
    "### Deflation-based Approach\n",
    "\n",
    "Find unmixing matrix rows one by one: $\\gamma_j = \\arg\\max \\sum\\limits_{k=1}^K (\\gamma_j' \\boldsymbol S_k \\gamma_j)^2$ under the constrain $\\gamma_j' \\boldsymbol S_k \\gamma_j = \\delta_{ij},\\ \\ i= 1,\\dots,j$. The solution optimizes the Lagrangian function.\n",
    "\n",
    "The estimateing equation:\n",
    "$$\n",
    "T(\\gamma_j)= \\boldsymbol S_0 \\bigg( \\sum\\limits_{r=1}^j \\gamma_r\\gamma_r'\\bigg) T(\\gamma_j)\n",
    "\\\\ \\text{where, }\\boldsymbol T (\\gamma) = \\sum\\limits_{k=1}^k ( \\boldsymbol{\\gamma'\\ S}_k \\boldsymbol\\gamma) \\boldsymbol S_k \\boldsymbol\\gamma\n",
    "$$\n",
    "\n",
    "As $\\boldsymbol\\Gamma = \\boldsymbol {US}_0^{-1/2}$, solve $u_j$ one by one (after $u_1,\\dots, u_{j-1}$ and init) following 2 steps until convergence\n",
    "$$\\begin{aligned} \n",
    "& T(u) := \\sum\\limits_{k=1}^K(u' \\boldsymbol R_k u) \\boldsymbol R_k u\n",
    "\\\\ \\text{step 1: } & u_j \\leftarrow \\bigg( \\boldsymbol I_p - \\sum\\limits_{i=1}^{j-1} u_i u_i' \\bigg)T(u_j)\n",
    "\\\\ \\text{step 2: } & u_j \\leftarrow ||u_j||^{-1}u_j\n",
    "\\\\ *\\ & \\text{different initial values should be tried.}\n",
    "\\end{aligned}$$\n",
    "\n",
    "### Symmetric Approach\n",
    "\n",
    "Simultaneously find all rows, and the estimating equations:\n",
    "$$\\begin{aligned}\n",
    "&\\begin{cases} \\gamma_i' T(\\gamma_j) = \\gamma_j\\ T(\\gamma_i)\n",
    "\\\\ \\gamma_i' \\boldsymbol S_0 \\gamma_j = \\delta_{ij}\n",
    "\\end{cases}\n",
    "\\\\ \\text{where, } & 2 T(\\gamma_j) = \\boldsymbol S_0 \\bigg( 2 \\theta_{jj}\\gamma_j + \\sum\\limits_{i=1}^{j-1}\\theta_{ij}\\gamma_i + \\sum\\limits_{i=j+1}^p \\theta_{ji}\\gamma_i \\bigg)\n",
    "\\\\ \\text{and } & \\boldsymbol T (\\gamma) = \\sum\\limits_{k=1}^k ( \\boldsymbol{\\gamma'\\ S}_k \\boldsymbol\\gamma) \\boldsymbol S_k \\boldsymbol\\gamma\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "Repeat until convergence\n",
    "$$\\begin{aligned} \n",
    "& T(u) := \\sum\\limits_{k=1}^K(u' \\boldsymbol R_k u) \\boldsymbol R_k u\n",
    "\\\\ \\text{step 1: } & T \\leftarrow (T(u_1), \\dots, T(u_p))'\n",
    "\\\\ \\text{step 2: } & U \\leftarrow (TT')^{-1/2} T\n",
    "\\end{aligned}$$\n",
    "\n",
    "## Another Intro to ICA and FOBI\n",
    "\n",
    "ICA is a BSS based $\\begin{cases} E(z)=0 \\\\ E(zz')= I_p \\\\ z\\text{ independent} \\end{cases}$, and the identifiability of parameters requires at most one component is normally distributed.\n",
    "\n",
    "Singular value decomposition $\\Omega=U\\Lambda V'$ and then $\\Sigma:=Cov(x)=U\\Lambda^2 U',\\ \\ VU'\\Sigma^{-1/2}(x-\\mu)=z$. Therefore, the orthogonal matrix $VU'$ is the components.\n",
    "\n",
    "Scatter matrices, $S_1, S_2$ (symmetric, positive definite and affine equivariant), and solve $\\begin{cases} \\Gamma S_1 \\Gamma'=I_p &\\text{standardization} \\\\ \\Gamma S_2 \\Gamma' = \\Lambda &\\text{uncorrelatoin}\\end{cases}$. The solution is eigenvector-eigenvalue of $S_1^{-1}S_2$\n",
    "\n",
    "FOBI chooses $\\begin{cases} S_1=Cov(x) \\\\ S_2 = E \\bigg( \\big(x-E(x)\\big)\\big(x-E(x)\\big)'\\ Cov(x)^{-1}\\ \\big(x-E(x)\\big)\\big(x-E(x)\\big)' \\bigg) \\end{cases}$\n",
    "\n",
    "## References\n",
    "\n",
    "<div class=\"btn-group btn-group-justified\" style=\"margin-top: 66px\">\n",
    "  <a href=\"https://r.boring.fi/files/bss/ref.jade.pkg.pdf\" class=\"btn btn-default\">JADE-BSS</a>\n",
    "  <a href=\"https://r.boring.fi/files/bss/ref.stationary.bss.pdf\" class=\"btn btn-default\">Stationary-TS</a>\n",
    "  <a href=\"https://r.boring.fi/files/bss/ref.tvsobi.intro.pdf\" class=\"btn btn-default\">TV-SOBI</a>\n",
    "  <a href=\"https://cran.r-project.org/web/packages/JADE/JADE.pdf\" class=\"btn btn-default\">JADE-CRAN</a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
